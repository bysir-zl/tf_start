# 初级版

原理就是用 一个[1,728] * [784, 10] 得到一个 [1,10]的代表数字比例的数组

机器学习的就是[784, 10]这个矩阵里面的权重, 由于只有这一层权重数组, 结果不是很准确 只有91%的准确度左右

在高级版, 会使用多层的卷积神经网络(CNN)

# 高级版

运用多层卷积和池化还有dropout提高准确性

不过要求的性能也很高, 1060显卡 测试需要20秒左右才能跑完 

## 知识点
**卷积和池化**: 卷积能提取图片特征, 池化能增强特征的不变性(可平移, 可缩放)

**dropout**: dropout 采用随机激活神经元的做法来防止过拟合

## 操作

要使用卷积就必须是一个4D向量, 所以第一步要把训练用的[1,728] reshape 为 [1,28,28,1] 分别代表batch(图片个数),height,weight,channels(颜色通道个数)

第二步: 卷积+池化

一般卷积之后都会接一个池化操作, 因为一般情况下 卷积会带来冗余数据而对特征识别没任何用处, 池化能去除冗余数据保留特征

我们使用一个filter`[5,5,1,32]`去卷积原始图像, 得到`[1,28,28,32]` 的卷积后的数据, 
紧接着步长为2池化得到`[1,14,14,32]`的数据

第三步: 再次卷积池化

用两层神经网络来得更准确吧

我们使用一个filter`[5,5,32,64]`去卷积上一步得到的数据, 得到`[1,14,14,64]` 的卷积后的数据, 
紧接着步长为2池化得到`[1,7,7,64]`的数据

第四步: 计算cross

为了能和结果y联系起来, 我们还是使用矩阵乘法将上一步的数据转换为`[1,10]`这个结构上来表示0-9的概率

具体操作: 将`[1,7,7,64]`reshape为`[1,7*7*64]` 乘以`[7*7*64,1024]`, 然后使用relu来激活这层得到下一层`[1,1024]`,
再使用dropout来防止过度拟合, 最后再乘以`[1024,10]`的矩阵得到`[1,10]`

第五步: 梯度下降优化

用梯度下降来降低损失, 学习上面众多神经元的权重,over.

## 小实验

我在基础版上添加了dropout, 能正常跑起来但是不会增加准确性

而添加了relu之后没有准确率只有0.1, 也就是乱猜的. 看来relu没那么简单 还得理解下