# 初级版

原理就是用 一个[1,728] * [784, 10] 得到一个 [1,10]的代表数字比例的数组

机器学习的就是[784, 10]这个矩阵里面的权重, 由于只有这一层权重数组, 结果不是很准确 只有91%的准确度左右

在高级版, 会使用多层的卷积神经网络(CNN)

> Q: 为什么一层权重数组不准确?
>
> A: 可能有以下问题: 
>  1. 通常来说多层要好一些: [深度学习中：”多层的好处是可以用较少的参数表示复杂的函数“这句话该怎么理解？](https://www.zhihu.com/question/22473246).
>  2. 不能很好的利用图片中的二维信息, 我们直觉是图片是二维比一维更好识别, 但是我们在这个例子中将图片拍平了.
>  3. 矩阵乘法是线性模型, 而手写样本可能不是线性可分的, 解决方法就是加入一个非线性的激活函数比如sigmoid, 
     为什么要使用激活函数请看[神经网络激励函数的作用是什么？有没有形象的解释？](https://www.zhihu.com/question/22334626)

# 高级版

运用多层卷积和池化还有dropout提高准确性

不过要求的性能也很高, 1060显卡 测试需要20秒左右才能跑完 

## 知识点
**卷积和池化**: 卷积能提取图片特征, 池化能增强特征的不变性(可平移, 可缩放)

**dropout**: dropout 采用随机激活神经元的做法来防止过拟合

## 操作

#### 第一步:reshape

卷积和池化是用来处理二维图像的, 所以要使用卷积就必须是一个4D向量, 所以第一步要把训练用的[1,728] reshape 为 [1,28,28,1] 分别代表batch(图片个数),height,width,channels(颜色通道个数)

#### 第二步: 卷积+池化

一般卷积之后都会接一个池化操作, 因为一般情况下 卷积会带来冗余数据而对特征识别没任何用处, 池化能去除冗余数据保留特征

我们使用一个filter`[5,5,1,32]`去卷积原始图像, 得到`[1,28,28,32]` 的卷积后的数据, 
紧接着步长为2池化得到`[1,14,14,32]`的数据

#### 第三步: 再次卷积池化

再次卷积池化的作用是将上一层的得到的初级特征(如一段曲线)再次组合成高级特征(如一个圆)以识别图片

我们使用一个filter`[5,5,32,64]`去卷积上一步得到的数据, 得到`[1,14,14,64]` 的卷积后的数据,
紧接着步长为2池化得到`[1,7,7,64]`的数据

#### 第四步: 计算cross

为了能和结果y联系起来, 我们还是使用矩阵乘法将上一步的数据转换为`[1,10]`这个结构上来表示0-9的概率

具体操作: 将`[1,7,7,64]`reshape为`[1,7*7*64]` 乘以`[7*7*64,1024]`, 然后使用relu来激活这层得到下一层`[1,1024]`,
再使用dropout来防止过度拟合, 最后再乘以`[1024,10]`的矩阵得到`[1,10]`

#### 第五步: 梯度下降优化

用梯度下降来降低损失, 学习上面众多神经元的权重,over.

## 小实验

我在基础版上添加了dropout, 能正常跑起来但是不会增加准确性
